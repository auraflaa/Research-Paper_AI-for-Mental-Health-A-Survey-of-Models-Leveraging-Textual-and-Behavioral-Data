# AI for Mental Health
## A Survey of Models Leveraging Textual and Behavioral Data

This repository contains the **complete reproduction package** for the systematic survey:

> **â€œAI for Mental Health: A Survey of Models Leveraging Textual and Behavioral Dataâ€**

The work examines AI-based detection of **Anxiety, Depression, and Stress (ADS)** using textual and behavioral signals, with a particular focus on **methodological rigor**, **evaluation validity**, and **deployment readiness** rather than headline accuracy improvements.

---

## ğŸ“Œ Abstract

Recent advances in Deep Learning for ADS detection frequently report substantial performance gains over classical approaches. However, through a systematic review and paired statistical analysis, we identify a **performance saturation plateau**â€”where increasingly complex architectures yield **diminishing returns** once controls for **data leakage**, **evaluation protocol rigor**, and **sample provenance** are enforced.

Using paired within-study comparisons, we observe statistically significant saturation:

- **Wilcoxon Signed-Rank Test:** p = 0.0244  
- **Cliffâ€™s Delta:** 0.5950 (large effect size)

To address the persistent gap between **research prototypes** and **deployable clinical systems**, we introduce an **Operational Readiness Checklist (ORC)**â€”a structured auditing framework for assessing whether a model meets minimum standards for responsible deployment.

---

## ğŸ“‚ Repository Structure

```text
Research-Paper_AI-for-Mental-Health/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ screening_log.csv       # PRISMA screening records (N=92)
â”‚   â”œâ”€â”€ study_extraction.csv    # Extracted features & metrics (N=27)
â”‚   â””â”€â”€ paired_comparisons.csv  # Data pairs for saturation hypothesis testing
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ validate_prism.py       # Validates data integrity & synchronization
â”‚   â”œâ”€â”€ analyze_saturation.py   # Statistical engine (Wilcoxon / Cliff's Delta)
â”‚   â””â”€â”€ generate_orc.py         # Generates Operational Readiness reports
â”‚
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ saturation_plot.pdf     # Visual evidence of the performance plateau
â”‚   â””â”€â”€ prisma_flow.pdf         # PRISMA 2020 inclusion flowchart
â”‚
â”œâ”€â”€ refs/                       # PDF artifacts & metadata placeholders
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ Reproduction Workflow

### 1. Environment Setup

```bash
git clone https://github.com/auraflaa/Research-Paper_AI-for-Mental-Health-A-Survey-of-Models-Leveraging-Textual-and-Behavioral-Data.git
cd Research-Paper_AI-for-Mental-Health-A-Survey-of-Models-Leveraging-Textual-and-Behavioral-Data
pip install -r requirements.txt
```

### 2. Data Integrity Check

Verify that the PRISMA screening log is synchronized with the extraction ledger.

```bash
python scripts/validate_prism.py
```

**Expected output:**

```
[PASS] All data artifacts verified for archive
```

### 3. Statistical Analysis (Saturation Hypothesis)

Compute paired statistical tests to evaluate performance saturation.

```bash
python scripts/analyze_saturation.py
```

**Validated results:**

- p-value: 0.0244 (significant at Î± = 0.05)  
- Cliffâ€™s Delta: 0.5950 (large effect)

### 4. Operational Readiness Audit

Generate model-level readiness classifications.

```bash
python scripts/generate_orc.py
```

---

## ğŸ›  Operational Readiness Checklist (ORC)

Models are evaluated on a 5-point scale across the following criteria:

1. **Provenance** â€” Clear disclosure of dataset origin  
2. **Modality** â€” Diversity and independence of input units  
3. **Rigor** â€” Use of cross-validation or leave-one-out protocols  
4. **Bias Mitigation** â€” Avoidance of synthetic oversampling (e.g., SMOTE)  
5. **Transparency** â€” Explicit reporting of sample size (N)

A score of **â‰¥ 4 / 5** is required for a model to be classified as **CLINICAL READY**.

---

## ğŸ“„ Citation

If you use this repository or its findings, please cite:

```bibtex
@article{MukherjeePandey2025ADS,
  title   = {AI for Mental Health: A Survey of Models Leveraging Textual and Behavioral Data},
  author  = {Mukherjee, Priyangshu and Pandey, Khusboo},
  journal = {Systematic Review Repository},
  year    = {2025},
  url     = {https://github.com/auraflaa/Research-Paper_AI-for-Mental-Health-A-Survey-of-Models-Leveraging-Textual-and-Behavioral-Data}
}
```

---

**Maintainer:** Priyangshu Mukherjee
